{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Описание задания\n",
        "Суть шифра Цезаря заключается в следующем: каждая буква алфавита заменяется на другую букву, смещённую на фиксированное число позиций вперёд или назад по алфавиту.\n",
        "\n",
        "В этом случае реализуются следующие шаги шифрования:\n",
        "\n",
        "* выбирается ключ (смещение), который определяет, насколько нужно сместить каждую букву.\n",
        "* каждая буква исходного текста заменяется на ту, которая находится на выбранное количество позиций позже в алфавите.\n",
        "\n",
        "### Задание:\n",
        "\n",
        "1. определите алфавит, с которым будете работать (совет: если выбираете русский язык, исключите букву «ё»);\n",
        "2. напишите алгоритм шифра Цезаря для генерации выборки (определите сдвиг на k каждой буквы, например, при сдвиге на 2 буква “А” переходит в букву “В” и так далее);\n",
        "3. постройте нейронную сеть и обучите ее по принципу: вход - зашифрованная фраза, выход - дешифрованная фраза;\n",
        "4. проверьте качество сети."
      ],
      "metadata": {
        "id": "m6__FdZCnzDu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjH6F7wGnsPd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выбрать алфавит\n",
        "alphabet = 'АБВГДЕЖЗИЙКЛМНОПРСТУФХЦЧШЩЪЫЬЭЮЯ'\n",
        "alphabet_size = len(alphabet)"
      ],
      "metadata": {
        "id": "AOVWeYdooMHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Алгоритм шифра Цезаря"
      ],
      "metadata": {
        "id": "2zpH44AzqSlN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Шифровщик\n",
        "def encrypt(text, k):\n",
        "    encrypted_text = ''\n",
        "\n",
        "    for char in text:\n",
        "        if char in alphabet:\n",
        "            index = alphabet.index(char)\n",
        "            new_index = (index + k) % alphabet_size\n",
        "            encrypted_text += alphabet[new_index]\n",
        "        else:\n",
        "            encrypted_text += char\n",
        "    return encrypted_text"
      ],
      "metadata": {
        "id": "UNwIS2Kgo0Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Дешифровщик\n",
        "def decrypt(text, k):\n",
        "    decrypted_text = ''\n",
        "\n",
        "    for char in text:\n",
        "        if char in alphabet:\n",
        "            index = alphabet.index(char)\n",
        "            new_index = (index - k) % alphabet_size\n",
        "            decrypted_text += alphabet[new_index]\n",
        "        else:\n",
        "            decrypted_text += char\n",
        "    return decrypted_text"
      ],
      "metadata": {
        "id": "JTgzPc8IpauY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Генерация датасета"
      ],
      "metadata": {
        "id": "blF4bXs3qZ5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_random_phrase(l=10):\n",
        "    return ''.join(random.choices(alphabet, k=l))\n",
        "\n",
        "def generate_dataset(n_samples, phrase_length=10, max_shift=5):\n",
        "    dataset = []\n",
        "\n",
        "    for _ in range(n_samples):\n",
        "        phrase = generate_random_phrase(phrase_length)\n",
        "        k = random.randint(1, max_shift)\n",
        "        encrypted_phrase = encrypt(phrase, k)\n",
        "        dataset.append((encrypted_phrase, phrase))\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "7LjQ7W5gpkX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование символов в индексы и обратно\n",
        "char_to_idx = {char: idx for idx, char in enumerate(alphabet)}\n",
        "idx_to_char = {idx: char for idx, char in enumerate(alphabet)}\n",
        "\n",
        "def phrase_to_tensor(phrase):\n",
        "    return torch.tensor([char_to_idx[char] for char in phrase], dtype=torch.long)\n",
        "\n",
        "def tensor_to_phrase(tensor):\n",
        "    return ''.join([idx_to_char[idx.item()] for idx in tensor])"
      ],
      "metadata": {
        "id": "3RwYxZ6qqwpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, train_ratio=0.8):\n",
        "    random.shuffle(dataset)\n",
        "    split_index = int(len(dataset) * train_ratio)\n",
        "    train_data = dataset[:split_index]\n",
        "    val_data = dataset[split_index:]\n",
        "    return train_data, val_data"
      ],
      "metadata": {
        "id": "tAAntdSIuEJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация датасета\n",
        "dataset = generate_dataset(2000, phrase_length=6, max_shift=3)\n",
        "\n",
        "# Разделить на обучающую и валидационную выборки\n",
        "train_data, val_data = split_dataset(dataset, train_ratio=0.8)"
      ],
      "metadata": {
        "id": "ltaaFu9Wrcys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Примеры из датасета:')\n",
        "for i, (encrypted, original) in enumerate(train_data[:10]):\n",
        "    print(f'Пример {i+1}:\\n   Зашифрованная фраза: {encrypted}\\n   Исходная фраза: {original}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jsE4WU0rphj",
        "outputId": "7c130428-ab95-4eec-f49a-919f3683044e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Примеры из датасета:\n",
            "Пример 1:\n",
            "   Зашифрованная фраза: ННЕЫЗД\n",
            "   Исходная фраза: ЛЛГЩЕВ\n",
            "\n",
            "Пример 2:\n",
            "   Зашифрованная фраза: НЮМЭТК\n",
            "   Исходная фраза: ЛЬКЫРИ\n",
            "\n",
            "Пример 3:\n",
            "   Зашифрованная фраза: ЪИЖЙАС\n",
            "   Исходная фраза: ШЖДЗЮП\n",
            "\n",
            "Пример 4:\n",
            "   Зашифрованная фраза: ЬЖХИЗШ\n",
            "   Исходная фраза: ЫЕФЗЖЧ\n",
            "\n",
            "Пример 5:\n",
            "   Зашифрованная фраза: ЙДЕЬТК\n",
            "   Исходная фраза: ЖБВЩПЗ\n",
            "\n",
            "Пример 6:\n",
            "   Зашифрованная фраза: ЩЛБЯМЯ\n",
            "   Исходная фраза: ЦИЮЬЙЬ\n",
            "\n",
            "Пример 7:\n",
            "   Зашифрованная фраза: ФДЩУХЩ\n",
            "   Исходная фраза: СБЦРТЦ\n",
            "\n",
            "Пример 8:\n",
            "   Зашифрованная фраза: ЙГАЧКШ\n",
            "   Исходная фраза: ИВЯЦЙЧ\n",
            "\n",
            "Пример 9:\n",
            "   Зашифрованная фраза: ЗКЧФВГ\n",
            "   Исходная фраза: ЕИХТАБ\n",
            "\n",
            "Пример 10:\n",
            "   Зашифрованная фраза: НСУЮХН\n",
            "   Исходная фраза: КОРЫТК\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Создать рекурентную сеть"
      ],
      "metadata": {
        "id": "ANg7Imtiq1Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CryptModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CryptModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, _ = self.rnn(embedded)\n",
        "        output = self.fc(rnn_out)\n",
        "        return output"
      ],
      "metadata": {
        "id": "V73bndS7rBA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "input_size = alphabet_size\n",
        "hidden_size = 64\n",
        "output_size = alphabet_size\n",
        "batch_size = 32\n",
        "n_epochs = 100\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "jheswM9itQxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создать экземпляр модели\n",
        "model = CryptModel(input_size, hidden_size, output_size)"
      ],
      "metadata": {
        "id": "3Sgoy3rArLXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Настройка оптимизатора и функции потерь"
      ],
      "metadata": {
        "id": "jyh3DbrVssIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "tgKBmlQ5spXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Обучение и оценка модели"
      ],
      "metadata": {
        "id": "It6aNU-Xs9OV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_data):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_chars = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encrypted, original in val_data:\n",
        "            encrypted_tensor = phrase_to_tensor(encrypted).unsqueeze(0)\n",
        "            original_tensor = phrase_to_tensor(original)\n",
        "\n",
        "            outputs = model(encrypted_tensor)\n",
        "            _, predicted = torch.max(outputs, dim=2)\n",
        "\n",
        "            total_correct += (predicted.squeeze(0) == original_tensor).sum().item()\n",
        "            total_chars += len(original)\n",
        "\n",
        "    accuracy = (total_correct / total_chars) * 100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "vapAg5aMu8QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, n_epochs, criterion, optimizer, batch_size):\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        # Обучение на обучающей выборке\n",
        "        for i in range(0, len(train_data), batch_size):\n",
        "            batch = train_data[i:i + batch_size]\n",
        "            encrypted_batch, original_batch = zip(*batch)\n",
        "\n",
        "            encrypted_tensors = [phrase_to_tensor(e) for e in encrypted_batch]\n",
        "            original_tensors = [phrase_to_tensor(o) for o in original_batch]\n",
        "\n",
        "            # Дополнение последовательностей до одинаковой длины\n",
        "            encrypted_tensors = torch.nn.utils.rnn.pad_sequence(encrypted_tensors, batch_first=True)\n",
        "            original_tensors = torch.nn.utils.rnn.pad_sequence(original_tensors, batch_first=True)\n",
        "\n",
        "            # Прямой проход\n",
        "            outputs = model(encrypted_tensors)  # (batch_size, seq_len, output_size)\n",
        "            loss = criterion(outputs.view(-1, output_size), original_tensors.view(-1))\n",
        "\n",
        "           # Обратный проход с оптимизатором\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Оценка на валидационной выборке\n",
        "        val_accuracy = evaluate(model, val_data)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss:.3f}, Val Accuracy: {val_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "HSnhbEiyudi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучить модель\n",
        "train(\n",
        "    model=model,\n",
        "    train_data=train_data,\n",
        "    val_data=val_data,\n",
        "    n_epochs=n_epochs,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWzzmlnTvTfz",
        "outputId": "7c219b21-31e5-46af-8353-93ee0f082e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 147.077, Val Accuracy: 33.208\n",
            "Epoch [2/100], Loss: 97.197, Val Accuracy: 33.292\n",
            "Epoch [3/100], Loss: 71.043, Val Accuracy: 34.417\n",
            "Epoch [4/100], Loss: 62.594, Val Accuracy: 33.375\n",
            "Epoch [5/100], Loss: 59.494, Val Accuracy: 35.125\n",
            "Epoch [6/100], Loss: 57.939, Val Accuracy: 32.667\n",
            "Epoch [7/100], Loss: 56.880, Val Accuracy: 32.417\n",
            "Epoch [8/100], Loss: 56.171, Val Accuracy: 33.083\n",
            "Epoch [9/100], Loss: 55.711, Val Accuracy: 34.125\n",
            "Epoch [10/100], Loss: 55.213, Val Accuracy: 31.583\n",
            "Epoch [11/100], Loss: 54.837, Val Accuracy: 33.333\n",
            "Epoch [12/100], Loss: 54.541, Val Accuracy: 33.458\n",
            "Epoch [13/100], Loss: 54.178, Val Accuracy: 33.500\n",
            "Epoch [14/100], Loss: 53.913, Val Accuracy: 34.250\n",
            "Epoch [15/100], Loss: 53.669, Val Accuracy: 34.083\n",
            "Epoch [16/100], Loss: 53.430, Val Accuracy: 34.875\n",
            "Epoch [17/100], Loss: 53.083, Val Accuracy: 33.167\n",
            "Epoch [18/100], Loss: 52.871, Val Accuracy: 33.583\n",
            "Epoch [19/100], Loss: 52.635, Val Accuracy: 33.333\n",
            "Epoch [20/100], Loss: 52.441, Val Accuracy: 32.375\n",
            "Epoch [21/100], Loss: 52.168, Val Accuracy: 33.958\n",
            "Epoch [22/100], Loss: 51.930, Val Accuracy: 33.417\n",
            "Epoch [23/100], Loss: 51.728, Val Accuracy: 31.875\n",
            "Epoch [24/100], Loss: 51.475, Val Accuracy: 33.292\n",
            "Epoch [25/100], Loss: 51.277, Val Accuracy: 31.917\n",
            "Epoch [26/100], Loss: 50.981, Val Accuracy: 32.500\n",
            "Epoch [27/100], Loss: 50.844, Val Accuracy: 33.583\n",
            "Epoch [28/100], Loss: 50.503, Val Accuracy: 33.833\n",
            "Epoch [29/100], Loss: 50.247, Val Accuracy: 32.750\n",
            "Epoch [30/100], Loss: 50.074, Val Accuracy: 33.000\n",
            "Epoch [31/100], Loss: 49.804, Val Accuracy: 32.875\n",
            "Epoch [32/100], Loss: 49.532, Val Accuracy: 32.417\n",
            "Epoch [33/100], Loss: 49.291, Val Accuracy: 32.208\n",
            "Epoch [34/100], Loss: 48.999, Val Accuracy: 32.583\n",
            "Epoch [35/100], Loss: 48.722, Val Accuracy: 32.875\n",
            "Epoch [36/100], Loss: 48.485, Val Accuracy: 33.667\n",
            "Epoch [37/100], Loss: 48.253, Val Accuracy: 33.500\n",
            "Epoch [38/100], Loss: 47.942, Val Accuracy: 32.792\n",
            "Epoch [39/100], Loss: 47.779, Val Accuracy: 32.042\n",
            "Epoch [40/100], Loss: 47.499, Val Accuracy: 31.667\n",
            "Epoch [41/100], Loss: 47.127, Val Accuracy: 32.750\n",
            "Epoch [42/100], Loss: 46.930, Val Accuracy: 32.083\n",
            "Epoch [43/100], Loss: 46.639, Val Accuracy: 33.417\n",
            "Epoch [44/100], Loss: 46.315, Val Accuracy: 32.500\n",
            "Epoch [45/100], Loss: 46.076, Val Accuracy: 31.917\n",
            "Epoch [46/100], Loss: 45.897, Val Accuracy: 33.417\n",
            "Epoch [47/100], Loss: 45.540, Val Accuracy: 32.667\n",
            "Epoch [48/100], Loss: 45.271, Val Accuracy: 32.375\n",
            "Epoch [49/100], Loss: 44.980, Val Accuracy: 32.958\n",
            "Epoch [50/100], Loss: 44.700, Val Accuracy: 33.083\n",
            "Epoch [51/100], Loss: 44.391, Val Accuracy: 32.542\n",
            "Epoch [52/100], Loss: 44.150, Val Accuracy: 31.667\n",
            "Epoch [53/100], Loss: 43.922, Val Accuracy: 32.458\n",
            "Epoch [54/100], Loss: 43.635, Val Accuracy: 32.708\n",
            "Epoch [55/100], Loss: 43.353, Val Accuracy: 32.042\n",
            "Epoch [56/100], Loss: 43.090, Val Accuracy: 32.625\n",
            "Epoch [57/100], Loss: 42.829, Val Accuracy: 32.125\n",
            "Epoch [58/100], Loss: 42.558, Val Accuracy: 32.625\n",
            "Epoch [59/100], Loss: 42.377, Val Accuracy: 32.792\n",
            "Epoch [60/100], Loss: 42.007, Val Accuracy: 32.958\n",
            "Epoch [61/100], Loss: 41.815, Val Accuracy: 32.125\n",
            "Epoch [62/100], Loss: 41.542, Val Accuracy: 32.792\n",
            "Epoch [63/100], Loss: 41.360, Val Accuracy: 32.500\n",
            "Epoch [64/100], Loss: 41.051, Val Accuracy: 32.125\n",
            "Epoch [65/100], Loss: 40.707, Val Accuracy: 32.875\n",
            "Epoch [66/100], Loss: 40.644, Val Accuracy: 32.167\n",
            "Epoch [67/100], Loss: 40.231, Val Accuracy: 32.542\n",
            "Epoch [68/100], Loss: 39.994, Val Accuracy: 31.917\n",
            "Epoch [69/100], Loss: 39.765, Val Accuracy: 33.208\n",
            "Epoch [70/100], Loss: 39.593, Val Accuracy: 32.625\n",
            "Epoch [71/100], Loss: 39.312, Val Accuracy: 32.458\n",
            "Epoch [72/100], Loss: 39.091, Val Accuracy: 32.125\n",
            "Epoch [73/100], Loss: 38.767, Val Accuracy: 33.125\n",
            "Epoch [74/100], Loss: 38.627, Val Accuracy: 32.292\n",
            "Epoch [75/100], Loss: 38.397, Val Accuracy: 33.458\n",
            "Epoch [76/100], Loss: 38.139, Val Accuracy: 32.083\n",
            "Epoch [77/100], Loss: 37.895, Val Accuracy: 32.583\n",
            "Epoch [78/100], Loss: 37.672, Val Accuracy: 32.542\n",
            "Epoch [79/100], Loss: 37.440, Val Accuracy: 32.042\n",
            "Epoch [80/100], Loss: 37.223, Val Accuracy: 32.792\n",
            "Epoch [81/100], Loss: 37.010, Val Accuracy: 32.417\n",
            "Epoch [82/100], Loss: 36.823, Val Accuracy: 32.375\n",
            "Epoch [83/100], Loss: 36.634, Val Accuracy: 32.875\n",
            "Epoch [84/100], Loss: 36.329, Val Accuracy: 32.417\n",
            "Epoch [85/100], Loss: 36.131, Val Accuracy: 33.083\n",
            "Epoch [86/100], Loss: 35.907, Val Accuracy: 31.917\n",
            "Epoch [87/100], Loss: 35.734, Val Accuracy: 32.583\n",
            "Epoch [88/100], Loss: 35.527, Val Accuracy: 32.167\n",
            "Epoch [89/100], Loss: 35.331, Val Accuracy: 31.833\n",
            "Epoch [90/100], Loss: 35.181, Val Accuracy: 32.167\n",
            "Epoch [91/100], Loss: 34.927, Val Accuracy: 31.958\n",
            "Epoch [92/100], Loss: 34.690, Val Accuracy: 31.958\n",
            "Epoch [93/100], Loss: 34.532, Val Accuracy: 31.917\n",
            "Epoch [94/100], Loss: 34.349, Val Accuracy: 32.250\n",
            "Epoch [95/100], Loss: 34.143, Val Accuracy: 32.167\n",
            "Epoch [96/100], Loss: 33.972, Val Accuracy: 32.167\n",
            "Epoch [97/100], Loss: 33.719, Val Accuracy: 32.792\n",
            "Epoch [98/100], Loss: 33.573, Val Accuracy: 32.042\n",
            "Epoch [99/100], Loss: 33.480, Val Accuracy: 32.583\n",
            "Epoch [100/100], Loss: 33.222, Val Accuracy: 32.375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранить модель\n",
        "torch.save(model.state_dict(), 'crypt_model.pth')"
      ],
      "metadata": {
        "id": "9FPmNIAqwAu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Протестировать модель"
      ],
      "metadata": {
        "id": "WO8u_xZZvvRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decrypt_with_model(model, encrypted_phrase):\n",
        "    encrypted_tensor = phrase_to_tensor(encrypted_phrase).unsqueeze(0)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(encrypted_tensor)\n",
        "        _, predicted = torch.max(outputs, dim=2)\n",
        "    return tensor_to_phrase(predicted.squeeze(0))"
      ],
      "metadata": {
        "id": "0G3Zlie7x5so"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model(model, n_tests=5):\n",
        "    print(\"Тестирование модели:\")\n",
        "    for i in range(n_tests):\n",
        "        test_phrase = generate_random_phrase(10)\n",
        "        k = random.randint(1, 5)\n",
        "        encrypted_test_phrase = encrypt(test_phrase, k)\n",
        "\n",
        "        predicted_phrase = decrypt_with_model(model, encrypted_test_phrase)\n",
        "\n",
        "        print(f'Тест {i+1}:\\n  Исходная фраза: {test_phrase}\\n  Зашифрованная фраза: {encrypted_test_phrase}\\n  Расшифрованная фраза: {predicted_phrase}\\n')"
      ],
      "metadata": {
        "id": "n-C-sZrawbmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели\n",
        "loaded_model = CryptModel(input_size, hidden_size, output_size)\n",
        "loaded_model.load_state_dict(torch.load(\"crypt_model.pth\"))\n",
        "loaded_model.eval()\n",
        "\n",
        "# Тестирование загруженной модели\n",
        "test_model(loaded_model, n_tests=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diegwvzswWEw",
        "outputId": "41b60c28-43fc-474b-b1fd-6d21c594f5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тестирование модели:\n",
            "Тест 1:\n",
            "  Исходная фраза: АБЧЯЫЙШУДЮ\n",
            "  Зашифрованная фраза: ДЕЫГЯНЬЧИВ\n",
            "  Расшифрованная фраза: БВЩАЬКЪЦЖА\n",
            "\n",
            "Тест 2:\n",
            "  Исходная фраза: ЛОСВЮХХВЬЭ\n",
            "  Зашифрованная фраза: ПТХЖВЩЩЖАБ\n",
            "  Расшифрованная фраза: НПФЕБЦЦГЮА\n",
            "\n",
            "Тест 3:\n",
            "  Исходная фраза: ХМАЪЧНРЖЧН\n",
            "  Зашифрованная фраза: ЪСЕЯЬТХЛЬТ\n",
            "  Расшифрованная фраза: ШРВЮЪСУЙЪС\n",
            "\n",
            "Тест 4:\n",
            "  Исходная фраза: ЭАОЛЧЖВОЪЙ\n",
            "  Зашифрованная фраза: БДТПЫКЖТЮН\n",
            "  Расшифрованная фраза: ЮБРОЪЙЕРЫК\n",
            "\n",
            "Тест 5:\n",
            "  Исходная фраза: БЭХНВЮЮУШЪ\n",
            "  Зашифрованная фраза: ВЮЦОГЯЯФЩЫ\n",
            "  Расшифрованная фраза: АЫХНВЭЮТЦШ\n",
            "\n",
            "Тест 6:\n",
            "  Исходная фраза: ПЪТЗПЮЯЬЯД\n",
            "  Зашифрованная фраза: СЬФЙСАБЮБЖ\n",
            "  Расшифрованная фраза: ПЫТЖОЯЮЫЮГ\n",
            "\n",
            "Тест 7:\n",
            "  Исходная фраза: ЦХФЗМЬТИБН\n",
            "  Зашифрованная фраза: ЧЦХИНЭУЙВО\n",
            "  Расшифрованная фраза: ЦХТЗКЫРЖАН\n",
            "\n",
            "Тест 8:\n",
            "  Исходная фраза: ПЬФДЪЧФНЮС\n",
            "  Зашифрованная фраза: ФБЩЙЯЬЩТГЦ\n",
            "  Расшифрованная фраза: ТЮШИЮЫЦПВУ\n",
            "\n",
            "Тест 9:\n",
            "  Исходная фраза: ЗЬХКЭЧОЖКЕ\n",
            "  Зашифрованная фраза: ЛАЩОБЫТКОЙ\n",
            "  Расшифрованная фраза: ЙЭШЛЮШСЙНЗ\n",
            "\n",
            "Тест 10:\n",
            "  Исходная фраза: ЛГМХЧЯПФЭТ\n",
            "  Зашифрованная фраза: ПЗРЩЫГУШБЦ\n",
            "  Расшифрованная фраза: НЕНШШАРХЯХ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как-то с реккурентной сетью не получилось, возможно она слишком сложная для этого простого действия, поэтому попробовала обычную архитектуру полносвязной нейросети"
      ],
      "metadata": {
        "id": "T1HVd_KiW5pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CryptModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(CryptModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.Softmax(dim=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        x = self.fc1(embedded)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.softmax(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "m4kO4hX5XHk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Параметры модели\n",
        "input_size = alphabet_size\n",
        "hidden_size = 64\n",
        "output_size = alphabet_size\n",
        "batch_size = 32\n",
        "n_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Создание экземпляра модели\n",
        "model = CryptModel(input_size, hidden_size, output_size)\n",
        "\n",
        "# Оптимизатор и функция потерь\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "r_3i--VcYHBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_data):\n",
        "    model.eval()\n",
        "    total_correct = 0\n",
        "    total_chars = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for encrypted, original in val_data:\n",
        "            encrypted_tensor = phrase_to_tensor(encrypted).unsqueeze(0)\n",
        "            original_tensor = phrase_to_tensor(original)\n",
        "\n",
        "            outputs = model(encrypted_tensor)\n",
        "            _, predicted = torch.max(outputs, dim=2)\n",
        "\n",
        "            total_correct += (predicted.squeeze(0) == original_tensor).sum().item()\n",
        "            total_chars += len(original)\n",
        "\n",
        "    accuracy = (total_correct / total_chars) * 100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "fiLM5dypY7yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, n_epochs, criterion, optimizer, batch_size):\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        random.shuffle(train_data)\n",
        "        total_loss = 0\n",
        "\n",
        "        # Обучение на обучающей выборке\n",
        "        for encrypted, original in train_data:\n",
        "            encrypted_tensor = phrase_to_tensor(encrypted).unsqueeze(0)\n",
        "            original_tensor = phrase_to_tensor(original)\n",
        "\n",
        "            # Прямой проход\n",
        "            outputs = model(encrypted_tensor)  # (1, seq_len, output_size)\n",
        "            loss = criterion(outputs.view(-1, output_size), original_tensor)\n",
        "\n",
        "            # Обратный проход с оптимизатором\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        # Оценка на валидационной выборке\n",
        "        val_accuracy = evaluate(model, val_data)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {total_loss:.3f}, Val Accuracy: {val_accuracy:.3f}')"
      ],
      "metadata": {
        "id": "-UhlL3ScYh-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train(\n",
        "    model=model,\n",
        "    train_data=train_data,\n",
        "    val_data=val_data,\n",
        "    n_epochs=n_epochs,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "# Сохранить модель\n",
        "torch.save(model.state_dict(), 'crypt_model2.pth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQBHIeFhaImj",
        "outputId": "0fe9c46e-b540-4fe8-c1be-2c62ed67a9bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 5151.608, Val Accuracy: 33.667\n",
            "Epoch [2/100], Loss: 5074.865, Val Accuracy: 33.458\n",
            "Epoch [3/100], Loss: 5073.173, Val Accuracy: 33.458\n",
            "Epoch [4/100], Loss: 5072.470, Val Accuracy: 33.167\n",
            "Epoch [5/100], Loss: 5065.206, Val Accuracy: 33.167\n",
            "Epoch [6/100], Loss: 5069.958, Val Accuracy: 33.833\n",
            "Epoch [7/100], Loss: 5062.104, Val Accuracy: 33.583\n",
            "Epoch [8/100], Loss: 5059.570, Val Accuracy: 33.833\n",
            "Epoch [9/100], Loss: 5057.343, Val Accuracy: 33.833\n",
            "Epoch [10/100], Loss: 5058.002, Val Accuracy: 33.833\n",
            "Epoch [11/100], Loss: 5058.124, Val Accuracy: 33.833\n",
            "Epoch [12/100], Loss: 5054.958, Val Accuracy: 33.583\n",
            "Epoch [13/100], Loss: 5052.470, Val Accuracy: 33.542\n",
            "Epoch [14/100], Loss: 5052.962, Val Accuracy: 33.375\n",
            "Epoch [15/100], Loss: 5052.359, Val Accuracy: 33.375\n",
            "Epoch [16/100], Loss: 5051.798, Val Accuracy: 33.458\n",
            "Epoch [17/100], Loss: 5051.920, Val Accuracy: 33.542\n",
            "Epoch [18/100], Loss: 5050.741, Val Accuracy: 33.542\n",
            "Epoch [19/100], Loss: 5051.425, Val Accuracy: 33.542\n",
            "Epoch [20/100], Loss: 5051.471, Val Accuracy: 33.542\n",
            "Epoch [21/100], Loss: 5050.728, Val Accuracy: 33.542\n",
            "Epoch [22/100], Loss: 5050.586, Val Accuracy: 33.542\n",
            "Epoch [23/100], Loss: 5050.778, Val Accuracy: 33.542\n",
            "Epoch [24/100], Loss: 5050.841, Val Accuracy: 33.875\n",
            "Epoch [25/100], Loss: 5050.761, Val Accuracy: 33.750\n",
            "Epoch [26/100], Loss: 5051.330, Val Accuracy: 33.750\n",
            "Epoch [27/100], Loss: 5051.267, Val Accuracy: 33.750\n",
            "Epoch [28/100], Loss: 5054.054, Val Accuracy: 33.875\n",
            "Epoch [29/100], Loss: 5054.526, Val Accuracy: 33.875\n",
            "Epoch [30/100], Loss: 5055.786, Val Accuracy: 33.000\n",
            "Epoch [31/100], Loss: 5074.450, Val Accuracy: 33.000\n",
            "Epoch [32/100], Loss: 5077.708, Val Accuracy: 33.083\n",
            "Epoch [33/100], Loss: 5075.661, Val Accuracy: 33.167\n",
            "Epoch [34/100], Loss: 5075.193, Val Accuracy: 33.167\n",
            "Epoch [35/100], Loss: 5075.056, Val Accuracy: 33.167\n",
            "Epoch [36/100], Loss: 5075.119, Val Accuracy: 33.167\n",
            "Epoch [37/100], Loss: 5095.467, Val Accuracy: 31.208\n",
            "Epoch [38/100], Loss: 5095.459, Val Accuracy: 31.667\n",
            "Epoch [39/100], Loss: 5089.469, Val Accuracy: 33.042\n",
            "Epoch [40/100], Loss: 5076.828, Val Accuracy: 33.042\n",
            "Epoch [41/100], Loss: 5076.531, Val Accuracy: 33.042\n",
            "Epoch [42/100], Loss: 5079.592, Val Accuracy: 33.208\n",
            "Epoch [43/100], Loss: 5074.684, Val Accuracy: 33.208\n",
            "Epoch [44/100], Loss: 5125.237, Val Accuracy: 30.208\n",
            "Epoch [45/100], Loss: 5131.020, Val Accuracy: 30.208\n",
            "Epoch [46/100], Loss: 5131.654, Val Accuracy: 30.333\n",
            "Epoch [47/100], Loss: 5133.156, Val Accuracy: 30.333\n",
            "Epoch [48/100], Loss: 5131.070, Val Accuracy: 30.292\n",
            "Epoch [49/100], Loss: 5129.175, Val Accuracy: 30.292\n",
            "Epoch [50/100], Loss: 5129.197, Val Accuracy: 30.292\n",
            "Epoch [51/100], Loss: 5129.026, Val Accuracy: 30.292\n",
            "Epoch [52/100], Loss: 5129.587, Val Accuracy: 30.292\n",
            "Epoch [53/100], Loss: 5130.988, Val Accuracy: 30.042\n",
            "Epoch [54/100], Loss: 5130.355, Val Accuracy: 30.042\n",
            "Epoch [55/100], Loss: 5129.962, Val Accuracy: 30.042\n",
            "Epoch [56/100], Loss: 5129.861, Val Accuracy: 30.042\n",
            "Epoch [57/100], Loss: 5131.090, Val Accuracy: 29.917\n",
            "Epoch [58/100], Loss: 5117.018, Val Accuracy: 30.750\n",
            "Epoch [59/100], Loss: 5114.459, Val Accuracy: 30.833\n",
            "Epoch [60/100], Loss: 5112.632, Val Accuracy: 30.833\n",
            "Epoch [61/100], Loss: 5110.482, Val Accuracy: 30.792\n",
            "Epoch [62/100], Loss: 5111.286, Val Accuracy: 30.792\n",
            "Epoch [63/100], Loss: 5112.551, Val Accuracy: 30.833\n",
            "Epoch [64/100], Loss: 5112.093, Val Accuracy: 30.792\n",
            "Epoch [65/100], Loss: 5111.707, Val Accuracy: 31.125\n",
            "Epoch [66/100], Loss: 5110.835, Val Accuracy: 31.125\n",
            "Epoch [67/100], Loss: 5110.978, Val Accuracy: 30.792\n",
            "Epoch [68/100], Loss: 5111.390, Val Accuracy: 30.792\n",
            "Epoch [69/100], Loss: 5111.915, Val Accuracy: 30.792\n",
            "Epoch [70/100], Loss: 5110.694, Val Accuracy: 30.792\n",
            "Epoch [71/100], Loss: 5110.452, Val Accuracy: 30.792\n",
            "Epoch [72/100], Loss: 5110.526, Val Accuracy: 31.125\n",
            "Epoch [73/100], Loss: 5110.553, Val Accuracy: 31.125\n",
            "Epoch [74/100], Loss: 5110.657, Val Accuracy: 31.125\n",
            "Epoch [75/100], Loss: 5110.745, Val Accuracy: 31.125\n",
            "Epoch [76/100], Loss: 5110.700, Val Accuracy: 31.125\n",
            "Epoch [77/100], Loss: 5110.965, Val Accuracy: 31.125\n",
            "Epoch [78/100], Loss: 5111.533, Val Accuracy: 30.792\n",
            "Epoch [79/100], Loss: 5111.088, Val Accuracy: 30.792\n",
            "Epoch [80/100], Loss: 5100.558, Val Accuracy: 32.125\n",
            "Epoch [81/100], Loss: 5095.446, Val Accuracy: 32.125\n",
            "Epoch [82/100], Loss: 5097.064, Val Accuracy: 32.125\n",
            "Epoch [83/100], Loss: 5096.475, Val Accuracy: 32.125\n",
            "Epoch [84/100], Loss: 5096.569, Val Accuracy: 32.125\n",
            "Epoch [85/100], Loss: 5095.981, Val Accuracy: 32.125\n",
            "Epoch [86/100], Loss: 5095.476, Val Accuracy: 32.125\n",
            "Epoch [87/100], Loss: 5095.288, Val Accuracy: 32.125\n",
            "Epoch [88/100], Loss: 5095.701, Val Accuracy: 32.125\n",
            "Epoch [89/100], Loss: 5095.160, Val Accuracy: 32.125\n",
            "Epoch [90/100], Loss: 5095.236, Val Accuracy: 32.125\n",
            "Epoch [91/100], Loss: 5095.315, Val Accuracy: 32.125\n",
            "Epoch [92/100], Loss: 5095.255, Val Accuracy: 32.125\n",
            "Epoch [93/100], Loss: 5094.808, Val Accuracy: 32.125\n",
            "Epoch [94/100], Loss: 5095.555, Val Accuracy: 32.125\n",
            "Epoch [95/100], Loss: 5097.552, Val Accuracy: 31.333\n",
            "Epoch [96/100], Loss: 5112.732, Val Accuracy: 31.333\n",
            "Epoch [97/100], Loss: 5113.728, Val Accuracy: 31.208\n",
            "Epoch [98/100], Loss: 5113.502, Val Accuracy: 31.333\n",
            "Epoch [99/100], Loss: 5113.881, Val Accuracy: 31.333\n",
            "Epoch [100/100], Loss: 5114.899, Val Accuracy: 31.333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка модели\n",
        "loaded_model = CryptModel(input_size, hidden_size, output_size)\n",
        "loaded_model.load_state_dict(torch.load(\"crypt_model2.pth\"))\n",
        "loaded_model.eval()\n",
        "\n",
        "# Тестирование загруженной модели\n",
        "test_model(loaded_model, n_tests=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFtQ8twbaJ0l",
        "outputId": "2c524ffa-e844-42d6-d166-14a15a24e013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Тестирование модели:\n",
            "Тест 1:\n",
            "  Исходная фраза: РОВЩЗНМЭЖФ\n",
            "  Зашифрованная фраза: ФТЖЭЛСРБКШ\n",
            "  Расшифрованная фраза: ТРДЪЙПОЮЙЧ\n",
            "\n",
            "Тест 2:\n",
            "  Исходная фраза: ДЧЫЬЙЛЮКЦЭ\n",
            "  Зашифрованная фраза: ЖЩЭЮЛНАМШЯ\n",
            "  Расшифрованная фраза: ДЧЪЫЙМЯЙЧЭ\n",
            "\n",
            "Тест 3:\n",
            "  Исходная фраза: ШЬЙЗЙЖЕГХЖ\n",
            "  Зашифрованная фраза: ЬАНЛНКЙЗЩК\n",
            "  Расшифрованная фраза: ЪЯМЙМЙИДЧЙ\n",
            "\n",
            "Тест 4:\n",
            "  Исходная фраза: ЖЭЙЮСЬСЧМВ\n",
            "  Зашифрованная фраза: ИЯЛАУЮУЩОД\n",
            "  Расшифрованная фраза: ЧЭЙЯРЫРЧМГ\n",
            "\n",
            "Тест 5:\n",
            "  Исходная фраза: ОЪИФМАЙРЛШ\n",
            "  Зашифрованная фраза: ПЫЙХНБКСМЩ\n",
            "  Расшифрованная фраза: ОЪИЬМЮЙПЙЧ\n",
            "\n",
            "Тест 6:\n",
            "  Исходная фраза: РШФЭЫЖИНСЦ\n",
            "  Зашифрованная фраза: УЫЧАЮЙЛРФЩ\n",
            "  Расшифрованная фраза: РЪЦЯЫИЙОТЧ\n",
            "\n",
            "Тест 7:\n",
            "  Исходная фраза: АРМЯГЬУБГУ\n",
            "  Зашифрованная фраза: БСНАДЭФВДФ\n",
            "  Расшифрованная фраза: ЮПМЯГЪТБГТ\n",
            "\n",
            "Тест 8:\n",
            "  Исходная фраза: ЙМЫЯКЫДЭЮЕ\n",
            "  Зашифрованная фраза: ОСАДПАЙВГК\n",
            "  Расшифрованная фраза: МПЯГОЯИБЫЙ\n",
            "\n",
            "Тест 9:\n",
            "  Исходная фраза: ЗЬУЯГЯЮКИЩ\n",
            "  Зашифрованная фраза: МБШДИДГПНЮ\n",
            "  Расшифрованная фраза: ЙЮЧГЧГЫОМЫ\n",
            "\n",
            "Тест 10:\n",
            "  Исходная фраза: ТТЗЭХГГПТЯ\n",
            "  Зашифрованная фраза: УУИЮЦДДРУА\n",
            "  Расшифрованная фраза: РРЧЫХГГОРЯ\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как-то и с полносвязной сетью не очень получилось...возможно, делаю что-то не так, но пока не поняла что"
      ],
      "metadata": {
        "id": "wWsx9BuQmFBi"
      }
    }
  ]
}