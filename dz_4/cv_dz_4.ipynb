{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Обучите модель Seq2Seq для перевода с английского на русский.\n",
        "\n",
        "Для этого:\n",
        "\n",
        "1. с сайта manythings.org выберите одну пару английских и русских предложений. Советуем выбрать ту пару предложений, которая не рассматривалась преподавателем на вебинаре.\n",
        "2. используйте загруженный набор данных для обучения модели последовательности к последовательности (Seq2Seq) по аналогии с проведенным занятием. После завершения процесса обучения оцените качество работы модели.\n",
        "3. добавьте еще один рекуррентный слой как в кодировщик (encoder), так и в декодировщик (decoder)\n",
        "4. замените используемые вами GRU-ячейки на LSTM-ячейки. Повторно обучите модель и сравните результаты с предыдущими версиями.\n",
        "5. сделайте выводы о качестве работы модели в каждом случае."
      ],
      "metadata": {
        "id": "hLv_OMLdFF0j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF6rpGdWFBsB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_sentences = [\n",
        "    'What is your name?',\n",
        "    'Where do you live?',\n",
        "    'How old are you?',\n",
        "    'I am from Russia.',\n",
        "    'Do you speak English?'\n",
        "]\n",
        "\n",
        "russian_sentences = [\n",
        "    'Как тебя зовут?',\n",
        "    'Где ты живешь?',\n",
        "    'Сколько тебе лет?',\n",
        "    'Я из России.',\n",
        "    'Ты говоришь по-английски?'\n",
        "]"
      ],
      "metadata": {
        "id": "_e6swKizGYKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создать словари и подготовить данные"
      ],
      "metadata": {
        "id": "TgKBq9ZyocSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создать словари для английского и русского языков\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK_token = 2"
      ],
      "metadata": {
        "id": "F3ZbREPTIgU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(sentence):\n",
        "    sentence = sentence.lower()\n",
        "    sentence = re.sub(r\"[^a-zA-Zа-яА-Я0-9\\s]\", \"\", sentence)\n",
        "    return sentence.split()"
      ],
      "metadata": {
        "id": "pXlZIwibY2lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {\"<SOS>\": SOS_token, \"<EOS>\": EOS_token, \"<UNK>\": UNK_token}\n",
        "        self.index2word = {SOS_token: \"<SOS>\", EOS_token: \"<EOS>\", UNK_token: \"<UNK>\"}\n",
        "        self.n_words = 3\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in tokenize(sentence):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "\n",
        "    def indexes_from_sentence(self, sentence):\n",
        "        return [self.word2index.get(word, self.word2index[\"<UNK>\"]) for word in tokenize(sentence)] + [EOS_token]"
      ],
      "metadata": {
        "id": "oRKJP_ciIr_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_lang = Lang(\"English\")\n",
        "output_lang = Lang(\"Russian\")"
      ],
      "metadata": {
        "id": "zSs44nwPVJT3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(eng_snt, rus_snt):\n",
        "    for eng, rus in zip(eng_snt, rus_snt):\n",
        "        input_lang.add_sentence(eng)\n",
        "        output_lang.add_sentence(rus)\n",
        "    return [(input_lang.indexes_from_sentence(eng), output_lang.indexes_from_sentence(rus))\n",
        "            for eng, rus in zip(eng_snt, rus_snt)]"
      ],
      "metadata": {
        "id": "8uRDOG91JHZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для преобразования пары предложений в тензоры\n",
        "def tensors_from_pair(pair):\n",
        "    input_tensor = torch.tensor(pair[0], dtype=torch.long).view(-1, 1)\n",
        "    target_tensor = torch.tensor(pair[1], dtype=torch.long).view(-1, 1)\n",
        "    return input_tensor, target_tensor"
      ],
      "metadata": {
        "id": "1trslM_yUIhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = prepare_data(english_sentences, russian_sentences)\n",
        "print(\"Содержимое pairs:\")\n",
        "for i, pair in enumerate(pairs):\n",
        "    print(f'Pair {i + 1}:')\n",
        "    print(f'  Вход (English): {pair[0]}')\n",
        "    print(f'  Выход (Russian): {pair[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtuSynZkJMR_",
        "outputId": "197aa13f-2388-4c39-b2fe-cc2f18eaf4b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Содержимое pairs:\n",
            "Pair 1:\n",
            "  Вход (English): [3, 4, 5, 6, 1]\n",
            "  Выход (Russian): [3, 4, 5, 1]\n",
            "Pair 2:\n",
            "  Вход (English): [7, 8, 9, 10, 1]\n",
            "  Выход (Russian): [6, 7, 8, 1]\n",
            "Pair 3:\n",
            "  Вход (English): [11, 12, 13, 9, 1]\n",
            "  Выход (Russian): [9, 10, 11, 1]\n",
            "Pair 4:\n",
            "  Вход (English): [14, 15, 16, 17, 1]\n",
            "  Выход (Russian): [12, 13, 14, 1]\n",
            "Pair 5:\n",
            "  Вход (English): [8, 9, 18, 19, 1]\n",
            "  Выход (Russian): [7, 15, 16, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка соответствия индексов словам\n",
        "print('\\nСловарь input_lang (English):')\n",
        "for idx, word in input_lang.index2word.items():\n",
        "    print(f'  {idx}: {word}')\n",
        "\n",
        "print('\\nСловарь output_lang (Russian):')\n",
        "for idx, word in output_lang.index2word.items():\n",
        "    print(f'  {idx}: {word}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYRFps_DVxqA",
        "outputId": "d6811456-7ce8-44df-fbec-c25788f82dc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Словарь input_lang (English):\n",
            "  0: <SOS>\n",
            "  1: <EOS>\n",
            "  2: <UNK>\n",
            "  3: what\n",
            "  4: is\n",
            "  5: your\n",
            "  6: name\n",
            "  7: where\n",
            "  8: do\n",
            "  9: you\n",
            "  10: live\n",
            "  11: how\n",
            "  12: old\n",
            "  13: are\n",
            "  14: i\n",
            "  15: am\n",
            "  16: from\n",
            "  17: russia\n",
            "  18: speak\n",
            "  19: english\n",
            "\n",
            "Словарь output_lang (Russian):\n",
            "  0: <SOS>\n",
            "  1: <EOS>\n",
            "  2: <UNK>\n",
            "  3: как\n",
            "  4: тебя\n",
            "  5: зовут\n",
            "  6: где\n",
            "  7: ты\n",
            "  8: живешь\n",
            "  9: сколько\n",
            "  10: тебе\n",
            "  11: лет\n",
            "  12: я\n",
            "  13: из\n",
            "  14: россии\n",
            "  15: говоришь\n",
            "  16: поанглийски\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создать модели и обучить их"
      ],
      "metadata": {
        "id": "XZfsi-6xojiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size)"
      ],
      "metadata": {
        "id": "EKZGyFX6Jg9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель + дополнительный слой\n",
        "class EncoderDeep(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderDeep, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=2)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size)\n",
        "\n",
        "class DecoderDeep(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderDeep, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, num_layers=2)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(2, 1, self.hidden_size)"
      ],
      "metadata": {
        "id": "JyQvI04OKV3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель + слои LSTM\n",
        "class EncoderLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n",
        "\n",
        "class DecoderLSTM(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderLSTM, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))"
      ],
      "metadata": {
        "id": "GRe9M5C6OMNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=10):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = torch.tensor(input_lang.indexes_from_sentence(sentence), dtype=torch.long)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        for i in range(input_tensor.size(0)):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "        decoder_input = torch.tensor([[SOS_token]])\n",
        "        decoder_hidden = encoder_hidden\n",
        "        decoded_words = []\n",
        "        for _ in range(max_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "KdYLZoU2OPfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, n_epochs=1000, tf_ratio=0.5, eval_interval=100):\n",
        "    for epoch in range(n_epochs):\n",
        "        pair = random.choice(pairs)\n",
        "        input_tensor, target_tensor = tensors_from_pair(pair)\n",
        "        encoder_hidden = encoder.init_hidden()\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "        input_length = input_tensor.size(0)\n",
        "        target_length = target_tensor.size(0)\n",
        "        loss = 0\n",
        "\n",
        "        # Прямой проход через кодировщик\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]])\n",
        "        decoder_hidden = encoder_hidden\n",
        "        use_tf = True if random.random() < tf_ratio else False\n",
        "\n",
        "        correct_words = 0\n",
        "        total_words = 0\n",
        "\n",
        "        if use_tf:\n",
        "            for i in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                loss += criterion(decoder_output, target_tensor[i])\n",
        "                decoder_input = target_tensor[i]\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                predicted_word = topi.squeeze().item()\n",
        "                correct_word = target_tensor[i].item()\n",
        "                if predicted_word == correct_word:\n",
        "                    correct_words += 1\n",
        "                total_words += 1\n",
        "        else:\n",
        "            for i in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                loss += criterion(decoder_output, target_tensor[i])\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze().detach()\n",
        "\n",
        "                # Расчет точности\n",
        "                predicted_word = topi.squeeze().item()\n",
        "                correct_word = target_tensor[i].item()\n",
        "                if predicted_word == correct_word:\n",
        "                    correct_words += 1\n",
        "                total_words += 1\n",
        "\n",
        "        accuracy = correct_words / total_words if total_words > 0 else 0\n",
        "\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f'Epoch {epoch}, Loss: {loss.item() / target_length:.3f}, Accuracy: {accuracy:.3f}')\n",
        "\n",
        "        if epoch % eval_interval == 0:\n",
        "            print('--- Evaluation ---')\n",
        "            test_sentence = random.choice(english_sentences)\n",
        "            print(f'Данные: {test_sentence}')\n",
        "            output_words = evaluate(encoder, decoder, test_sentence)\n",
        "            output_sentence = ' '.join(output_words)\n",
        "            print(f'Предсказание: {output_sentence}\\n')"
      ],
      "metadata": {
        "id": "If2Ql5JrQnJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель\n",
        "encoder = Encoder(input_lang.n_words, 256)\n",
        "decoder = Decoder(256, output_lang.n_words)\n",
        "\n",
        "encoder_optimizer = optim.SGD(encoder.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(decoder.parameters(), lr=0.01)\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "train(encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, n_epochs=1000, eval_interval=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH43fJQTRv03",
        "outputId": "2db842bf-3cbe-408e-9aed-1e8eb3405ee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.906, Accuracy: 0.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь говоришь говоришь говоришь говоришь говоришь говоришь говоришь говоришь\n",
            "\n",
            "Epoch 100, Loss: 0.631, Accuracy: 1.000\n",
            "Epoch 200, Loss: 0.103, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 300, Loss: 0.057, Accuracy: 1.000\n",
            "Epoch 400, Loss: 0.043, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: What is your name?\n",
            "Предсказание: как тебя зовут <EOS>\n",
            "\n",
            "Epoch 500, Loss: 0.025, Accuracy: 1.000\n",
            "Epoch 600, Loss: 0.027, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: What is your name?\n",
            "Предсказание: как тебя зовут <EOS>\n",
            "\n",
            "Epoch 700, Loss: 0.015, Accuracy: 1.000\n",
            "Epoch 800, Loss: 0.013, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 900, Loss: 0.009, Accuracy: 1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы**:\n",
        "Базовая модель быстро обучается и достигает высокой точности (1.000) уже к 200-й эпохе. Однако качество перевода в начале обучения низкое, что может быть связано с простотой архитектуры и ограниченностью данных."
      ],
      "metadata": {
        "id": "fhkEB9MjqMjW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель + дополнительный слой\n",
        "encoder_deep = EncoderDeep(input_lang.n_words, 256)\n",
        "decoder_deep = DecoderDeep(256, output_lang.n_words)\n",
        "\n",
        "encoder_optimizer = optim.SGD(encoder_deep.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(decoder_deep.parameters(), lr=0.01)\n",
        "\n",
        "train(encoder_deep, decoder_deep, encoder_optimizer, decoder_optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJfRo4_vRyvd",
        "outputId": "dc35a3b5-ed50-442a-8c9c-44ff864c0dad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.801, Accuracy: 0.000\n",
            "--- Evaluation ---\n",
            "Данные: Where do you live?\n",
            "Предсказание: живешь тебя зовут тебя тебя тебя тебя зовут тебя тебя\n",
            "\n",
            "Epoch 100, Loss: 1.203, Accuracy: 0.750\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты ты <EOS>\n",
            "\n",
            "Epoch 200, Loss: 0.415, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 300, Loss: 0.211, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: What is your name?\n",
            "Предсказание: как тебя зовут <EOS>\n",
            "\n",
            "Epoch 400, Loss: 0.067, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 500, Loss: 0.088, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 600, Loss: 0.039, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 700, Loss: 0.036, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 800, Loss: 0.019, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 900, Loss: 0.022, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы**: Добавление дополнительного слоя улучшает способность модели обрабатывать сложные зависимости, но замедляет процесс обучения. Начальная точность выше, чем у базовой модели, что указывает на лучшую способность захватывать контекст. Однако время, необходимое для достижения точности 1.000, увеличивается."
      ],
      "metadata": {
        "id": "3LS_tLfyqXP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Базовая модель + слои LSTM\n",
        "encoder_lstm = EncoderLSTM(input_lang.n_words, 256)\n",
        "decoder_lstm = DecoderLSTM(256, output_lang.n_words)\n",
        "\n",
        "encoder_optimizer = optim.SGD(encoder_lstm.parameters(), lr=0.01)\n",
        "decoder_optimizer = optim.SGD(decoder_lstm.parameters(), lr=0.01)\n",
        "\n",
        "train(encoder_lstm, decoder_lstm, encoder_optimizer, decoder_optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BrSvKYWR5n9",
        "outputId": "006e68c2-fbe8-4528-a8a2-324cced42bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.816, Accuracy: 0.000\n",
            "--- Evaluation ---\n",
            "Данные: What is your name?\n",
            "Предсказание: я <EOS>\n",
            "\n",
            "Epoch 100, Loss: 1.913, Accuracy: 0.250\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n",
            "Epoch 200, Loss: 2.203, Accuracy: 0.250\n",
            "--- Evaluation ---\n",
            "Данные: Where do you live?\n",
            "Предсказание: где ты живешь <EOS>\n",
            "\n",
            "Epoch 300, Loss: 0.323, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 400, Loss: 0.078, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: I am from Russia.\n",
            "Предсказание: я из россии <EOS>\n",
            "\n",
            "Epoch 500, Loss: 0.062, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 600, Loss: 0.032, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: I am from Russia.\n",
            "Предсказание: я из россии <EOS>\n",
            "\n",
            "Epoch 700, Loss: 0.025, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Where do you live?\n",
            "Предсказание: где ты живешь <EOS>\n",
            "\n",
            "Epoch 800, Loss: 0.029, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: How old are you?\n",
            "Предсказание: сколько тебе лет <EOS>\n",
            "\n",
            "Epoch 900, Loss: 0.023, Accuracy: 1.000\n",
            "--- Evaluation ---\n",
            "Данные: Do you speak English?\n",
            "Предсказание: ты говоришь поанглийски <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Выводы**: Модель с LSTM демонстрирует самое медленное обучение в начале, но затем быстро догоняет другие модели. После 300 эпох она достигает точности 1.000, что указывает на высокое качество перевода."
      ],
      "metadata": {
        "id": "Fw48YQBOqezq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Общие выводы:**\n",
        "* Базовая модель обучается быстрее всех, но её простота может ограничивать её способность обрабатывать сложные зависимости.\n",
        "* Добавление дополнительного слоя улучшает способность модели обобщать данные, но замедляет обучение.\n",
        "* Увеличение глубины сети или использование LSTM повышает качество перевода, но также увеличивает вычислительные затраты."
      ],
      "metadata": {
        "id": "Ct9uy3yfqm8V"
      }
    }
  ]
}